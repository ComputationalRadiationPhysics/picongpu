from snakemake.utils import Paramspace
import pandas as pd
import os

current_dir=os.getcwd()
input_params="params.tsv"
output_params="new_params.tsv"

# define a paramspace
# filename_params defines naming and directory structure of every instance of the parameter space
paramspace = Paramspace(pd.read_csv(input_params, sep="\t"), filename_params="*", param_sep="-") 

# declare which rule should not be executed on cluster
localrules: all, simulate

# target rule, defines entire anticipated output
rule all:
    input: output_params

# compile for every parameter instance
rule compile:
     input:
         pic_project="path_to/picongpu_project",
         pic_profile="path_to_profile/picongpu.profile"
     # to use the paramspace naming pattern use python f-string formatting    
     output:  directory(f"path_to_simulations/sim_{paramspace.wildcard_pattern}")
     resources: # define needed cluster resources
         slurm_partition="fwkt_v100",
         slurm_account="fwkt_v100",
         runtime=60,
         nodes=1,
         ntasks=4,
         cpus_per_task=6,
         mem_mb=378000,
         slurm="gres=gpu:1"
     params:
         # access one parameter set with the instance methode
         sim_params=paramspace.instance,
         # define name to use paramspace naming pattern in shell commands
         name=f"{paramspace.wildcard_pattern}"
     retries: 2 # defines number of retries if execution fails
     shell:
         """
         source {input.pic_profile}
         pic-create {input.pic_project} projects/run_{params.name}/
         cd projects/run_{params.name}/
         # append touch command to .tpl -> creates file when simulation is finished
         echo "if [[ ! -z \`grep \\\"100 % =\\\" output\` ]]; then touch ../../../simulated/finished_{params.name}.txt; fi" >> etc/picongpu/hemera-hzdr/fwkt_v100.tpl
         # parameter dependent compile
         pic-build -c "-DPARAM_OVERWRITES:LIST='-DPARAM_A0={params.sim_params[A0]};-DPARAM_PULSE_DURATION_SI={params.sim_params[PULSEDURATION]}'"
         # create simulation directory, define which cfg should be used
         tbg -c etc/picongpu/4_test.cfg -t etc/picongpu/hemera-hzdr/fwkt_v100.tpl {current_dir}/{output}
        """

# start and track simulation
rule simulate:
    input: f"simulations/sim_{paramspace.wildcard_pattern}"
    output: f"simulated/finished_{paramspace.wildcard_pattern}.txt"
    params:
        name=f"{paramspace.wildcard_pattern}"
    retries: 3
    shell:
         """         
         # if no job id is known -> start simulation
         if ! [ -f simulated/job_id_{params.name}.txt ]; then
             sbatch {input}/tbg/submit.start > simulated/job_id_{params.name}.txt
         fi

         job_id=$(cut -c 21-27 simulated/job_id_{params.name}.txt
         status=$(squeue --jobs $job_id -o "%2t" | tail -n 1 )

         # if job isn't running or pending -> restart job
         if ! [[ "$status" == "PD" || "$status" == "R " ]]; then
             sbatch {input}/tbg/submit.start >  simulated/job_id_{params.name}.txt
             job_id=$(cut -c 21-27 simulated/job_id_{params.name}.txt)
             status=$(squeue --jobs $job_id -o "%2t" | tail -n 1 )
         fi
         # wait till job is finished
         while [[ "$status" == "PD" || "$status" == "R " ]]
         do
             sleep 30
             status=$(squeue --jobs $job_id -o "%2t" | tail -n 1 )
         done
         """

# simple example of python post processing
rule post_processing:
    input:
        f"simulated/finished_{paramspace.wildcard_pattern}.txt"
    output: 
        f"results/result_{paramspace.wildcard_pattern}.npy"
    resources:
         slurm_partition="defq",
         runtime=60,  # [min]
         nodes=1,
         ntasks=20,
         mem_mb=95000
    # groups allow to execute multiple task in one slurm job (works for multiple tasks of a kind or different tasks)
    group: "group1"
    params:
        name=f"{paramspace.wildcard_pattern}",
        sim_dir=f"simulations/sim_{paramspace.wildcard_pattern}/simOutput/openPMD"
    script:
        "path_to_script/post_processing.py"

# example rule of post processing that requires output from each parameter set 
rule optimization:
    input: 
        current_params=input_params,
        post_processing_results=expand("results/result_{params}.npy", params=paramspace.instance_patterns)
    output: 
        new_params=output_params
    resources:
         slurm_partition="defq",
         runtime=60,
         nodes=1,
         ntasks=20,
         mem_mb=95000 
    params:
        n_new_params=5
    script:
        "path_to_script/optimization.py"
