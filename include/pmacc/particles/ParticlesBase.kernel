/* Copyright 2013-2019 Felix Schmitt, Heiko Burau, Rene Widera
 *
 * This file is part of PMacc.
 *
 * PMacc is free software: you can redistribute it and/or modify
 * it under the terms of either the GNU General Public License or
 * the GNU Lesser General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * PMacc is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License and the GNU Lesser General Public License
 * for more details.
 *
 * You should have received a copy of the GNU General Public License
 * and the GNU Lesser General Public License along with PMacc.
 * If not, see <http://www.gnu.org/licenses/>.
 */

#include "pmacc/types.hpp"
#include "pmacc/particles/memory/boxes/ParticlesBox.hpp"
#include "pmacc/particles/memory/boxes/PushDataBox.hpp"
#include "pmacc/particles/memory/boxes/TileDataBox.hpp"
#include "pmacc/dimensions/DataSpaceOperations.hpp"
#include "pmacc/mappings/kernel/ExchangeMapping.hpp"
#include "pmacc/particles/memory/boxes/ExchangePushDataBox.hpp"
#include "pmacc/particles/memory/boxes/ExchangePopDataBox.hpp"
#include "pmacc/memory/CtxArray.hpp"
#include "pmacc/mappings/threads/ForEachIdx.hpp"
#include "pmacc/mappings/threads/IdxConfig.hpp"

#include "pmacc/particles/operations/Assign.hpp"
#include "pmacc/particles/operations/Deselect.hpp"
#include "pmacc/traits/NumberOfExchanges.hpp"
#include "pmacc/nvidia/atomic.hpp"
#include "pmacc/memory/shared/Allocate.hpp"
#include "pmacc/memory/Array.hpp"

namespace pmacc
{

template<typename T_ParticleBox, typename T_SuperCellIdxType>
DINLINE typename T_ParticleBox::FramePtr
getPreviousFrameAndRemoveLastFrame( const typename T_ParticleBox::FramePtr& frame,
                                    T_ParticleBox& pb,
                                    const T_SuperCellIdxType& superCellIdx )
{
    typename T_ParticleBox::FramePtr result = pb.getPreviousFrame( frame );
    pb.removeLastFrame( superCellIdx );
    return result;
}

/** fill particle gaps in the last frame
 *
 * Copy all particles in a frame to the storage places at the frame's beginning.
 * This leaves the frame with a contiguous number of valid particles at
 * the beginning and a subsequent, contiguous gap at the end.
 *
 * @tparam T_numWorkers number of workers
 */
template< uint32_t T_numWorkers >
struct KernelFillGapsLastFrame
{
    /** fill particle gaps
     *
     * @tparam T_ParBox pmacc::ParticlesBox, particle box type
     * @tparam T_Mapping mapper functor type
     *
     * @param boxPar particle memory
     * @param mapper functor to map a block to a supercell
     */
    template<
        typename T_ParBox,
        typename T_Mapping,
        typename T_Acc
    >
    DINLINE void operator()(
        T_Acc const & acc,
        T_ParBox pb,
        T_Mapping mapper
    ) const
    {
        using namespace particles::operations;
        using namespace mappings::threads;

        constexpr uint32_t frameSize = math::CT::volume<typename T_Mapping::SuperCellSize>::type::value;
        constexpr uint32_t dim = T_Mapping::Dim;
        constexpr uint32_t numWorkers = T_numWorkers;

        using FramePtr = typename T_ParBox::FramePtr;

        DataSpace< dim > const superCellIdx = mapper.getSuperCellIndex( DataSpace< dim > ( blockIdx ) );

        PMACC_SMEM(
            acc,
            lastFrame,
            FramePtr
        );
        PMACC_SMEM(
            acc,
            gapIndices_sh,
            memory::Array<
                int,
                frameSize
            >
        );
        PMACC_SMEM(
            acc,
            counterGaps,
            int
        );
        PMACC_SMEM(
            acc,
            counterParticles,
            int
        );
        PMACC_SMEM(
            acc,
            srcGap,
            int
        );

        uint32_t const workerIdx = threadIdx.x;

        using MasterOnly = IdxConfig<
            1,
            numWorkers
        >;

        ForEachIdx< MasterOnly >{ workerIdx }(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                lastFrame = pb.getLastFrame( superCellIdx );
                counterGaps = 0;
                counterParticles = 0;
                srcGap = 0;
            }
        );

        __syncthreads( );

        if ( lastFrame.isValid( ) )
        {
            using ParticleDomCfg = IdxConfig<
                frameSize,
                numWorkers
            >;

            /* context if an element within the frame is a particle */
            memory::CtxArray<
                bool,
                ParticleDomCfg
            >
            isParticleCtx(
                workerIdx,
                [&](
                    uint32_t const linearIdx,
                    uint32_t const
                )
                {
                    return lastFrame[ linearIdx ][ multiMask_ ];
                }
            );

            /* loop over all particles in the frame */
            ForEachIdx< ParticleDomCfg > forEachParticle( workerIdx );

            // count particles in last frame
            forEachParticle(
                [&](
                    uint32_t const,
                    uint32_t const idx
                )
                {
                    if( isParticleCtx[ idx ] )
                        nvidia::atomicAllInc( acc, &counterParticles, ::alpaka::hierarchy::Threads{} );
                }
            );

            __syncthreads( );

            forEachParticle(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const idx
                )
                {
                    if ( linearIdx < counterParticles && isParticleCtx[ idx ] == false )
                    {
                        int const localGapIdx = nvidia::atomicAllInc( acc, &counterGaps, ::alpaka::hierarchy::Threads{} );
                        gapIndices_sh[ localGapIdx ] = linearIdx;
                    }
                }
            );
            __syncthreads( );
            forEachParticle(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const idx
                )
                {
                    if ( linearIdx >= counterParticles && isParticleCtx[ idx ] )
                    {
                        // any particle search a gap
                        int const srcGapIdx = nvidia::atomicAllInc( acc, &srcGap, ::alpaka::hierarchy::Threads{} );
                        int const gapIdx = gapIndices_sh[ srcGapIdx ];
                        auto parDestFull = lastFrame[ gapIdx ];
                        /* enable particle */
                        parDestFull[ multiMask_ ] = 1;
                        /* we do not update the multiMask because copying from mem to mem is too slow
                         * we have to enabled particles explicitly
                         */
                        auto parDest = deselect< multiMask >( parDestFull );
                        auto parSrc = ( lastFrame[ linearIdx ] );
                        assign( parDest, parSrc );
                        parSrc[multiMask_] = 0; // delete old particle
                    }
                }
            );
        }
        ForEachIdx< MasterOnly >{ workerIdx }(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                // there is no need to add a zero to the global memory
                if( counterParticles != 0 )
                {
                    auto & superCell = pb.getSuperCell( superCellIdx );
                    superCell.setNumParticles(
                        superCell.getNumParticles() + counterParticles
                    );
                }
                else
                {
                    /* The last frame is empty therefore it must be removed.
                     * It is save to call this method even if there is no last frame.
                     */
                    pb.removeLastFrame( superCellIdx );
                }
            }
        );
    }
};

/** fill particle gaps in all frames
 *
 * Copy all particles from the end to the gaps at the beginning of the frame list.
 * The functor fulfills the restriction that the last frame must be hold a contiguous
 * number of valid particles at the beginning and a subsequent, contiguous gap at the end.
 *
 * @tparam T_numWorkers number of workers
 */
template< uint32_t T_numWorkers >
struct KernelFillGaps
{
    /** fill particle gaps
     *
     * @tparam T_ParBox pmacc::ParticlesBox, particle box type
     * @tparam T_Mapping mapper functor type
     *
     * @param pb particle memory
     * @param mapper functor to map a block to a supercell
     */
    template<
        typename T_ParBox,
        typename T_Mapping,
        typename T_Acc
    >
    DINLINE void operator()(
        T_Acc const & acc,
        T_ParBox pb,
        T_Mapping const mapper
    ) const
    {
        using namespace particles::operations;
        using namespace mappings::threads;

        using FramePtr = typename T_ParBox::FramePtr;

        constexpr uint32_t frameSize = math::CT::volume< typename T_ParBox::FrameType::SuperCellSize >::type::value;
        constexpr uint32_t dim = T_Mapping::Dim;
        constexpr uint32_t numWorkers = T_numWorkers;

        uint32_t const workerIdx = threadIdx.x;

        DataSpace< dim > const superCellIdx( mapper.getSuperCellIndex( DataSpace< dim >( blockIdx ) ) );

        // data copied from right (last) to left (first)
        PMACC_SMEM(
            acc,
            firstFrame,
            FramePtr
        );
        PMACC_SMEM(
            acc,
            lastFrame,
            FramePtr
        );

        PMACC_SMEM(
            acc,
            particleIndices_sh,
            memory::Array<
                int,
                frameSize
            >
        );
        // number of gaps in firstFrame frame
        PMACC_SMEM(
            acc,
            counterGaps,
            int
        );
        // number of particles in the lastFrame
        PMACC_SMEM(
            acc,
            counterParticles,
            int
        );

        uint32_t numParticlesPerSuperCell = 0u;

        ForEachIdx<
            IdxConfig<
                1,
                numWorkers
            >
        > onlyMaster{ workerIdx };

        onlyMaster(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                firstFrame = pb.getFirstFrame( superCellIdx );
                lastFrame = pb.getLastFrame( superCellIdx );
            }
        );

        __syncthreads( );

        while ( firstFrame.isValid( ) && firstFrame != lastFrame )
        {
            onlyMaster(
                [&](
                    uint32_t const,
                    uint32_t const
                )
                {
                    counterGaps = 0;
                    counterParticles = 0;
                }
            );

            __syncthreads( );

            using ParticleDomCfg = IdxConfig<
                frameSize,
                numWorkers
            >;
            // loop over all particles in the frame
            ForEachIdx< ParticleDomCfg > forEachParticle( workerIdx );

            memory::CtxArray<
                int,
                ParticleDomCfg
            > localGapIdxCtx( INV_LOC_IDX );

            // find gaps in firstFrame
            forEachParticle(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const idx
                )
                {
                    if( firstFrame[ linearIdx ][ multiMask_ ] == 0 )
                    {
                        localGapIdxCtx[ idx ] = nvidia::atomicAllInc( acc, &counterGaps, ::alpaka::hierarchy::Threads{} );
                    }
                }
            );

            __syncthreads( );

            if( counterGaps != 0 )
            {
                // count particles in lastFrame
                forEachParticle(
                    [&](
                        uint32_t const linearIdx,
                        uint32_t const idx
                    )
                    {
                        // search particles for gaps
                        if( lastFrame[ linearIdx ][ multiMask_ ] == 1 )
                        {
                            int const localParticleIdx = nvidia::atomicAllInc( acc, &counterParticles, ::alpaka::hierarchy::Threads{} );
                            particleIndices_sh[ localParticleIdx ] = linearIdx;
                        }
                    }
                );

                __syncthreads( );

                // copy particles from lastFrame to the gaps in firstFrame
                forEachParticle(
                    [&](
                        uint32_t const linearIdx,
                        uint32_t const idx
                    )
                    {
                        if( localGapIdxCtx[ idx ] < counterParticles )
                        {
                            int const parIdx = particleIndices_sh[ localGapIdxCtx[ idx ] ];
                            auto parDestFull = firstFrame[ linearIdx ];
                            // enable particle
                            parDestFull[ multiMask_ ] = 1;
                            /* we not update multiMask because copy from mem to mem is to slow
                             * we have enabled particle explicit
                             */
                            auto parDest = deselect< multiMask >( parDestFull );
                            auto parSrc = lastFrame[ parIdx ];
                            assign( parDest, parSrc );
                            parSrc[ multiMask_ ] = 0;
                        }
                    }
                );

                __syncthreads( );

                onlyMaster(
                    [&](
                        uint32_t const,
                        uint32_t const
                    )
                    {
                        if( counterGaps < counterParticles )
                        {
                            numParticlesPerSuperCell += frameSize;
                            // any gap in the first frame is filled
                            firstFrame = pb.getNextFrame( firstFrame );
                        }
                        else if( counterGaps > counterParticles )
                        {
                            // we need more particles
                            lastFrame = getPreviousFrameAndRemoveLastFrame(
                                lastFrame,
                                pb,
                                superCellIdx
                            );
                        }
                        else if( counterGaps == counterParticles )
                        {
                            // update lastFrame and firstFrame
                            lastFrame = getPreviousFrameAndRemoveLastFrame(
                                lastFrame,
                                pb,
                                superCellIdx
                            );
                            if( lastFrame.isValid( ) && lastFrame != firstFrame )
                            {
                                numParticlesPerSuperCell += frameSize;
                                firstFrame = pb.getNextFrame( firstFrame );
                            }
                        }
                    }
                );
            }
            else
            {
                // there are no gaps in firstFrame, goto to next frame
                onlyMaster(
                    [&](
                        uint32_t const,
                        uint32_t const
                    )
                    {
                        numParticlesPerSuperCell += frameSize;
                        firstFrame = pb.getNextFrame( firstFrame );
                    }
                );
            }

            __syncthreads( );

        }

        onlyMaster(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                /* numParticlesPerSuperCell is the number of particles in the
                 * supercell except the particles in the last frame
                 */
                auto & superCell = pb.getSuperCell( superCellIdx );
                superCell.setNumParticles( numParticlesPerSuperCell );
            }
        );

        // fill all gaps in the last frame of the supercell
        KernelFillGapsLastFrame< numWorkers >{ }(
            acc,
            pb,
            mapper
        );
    }
};

/** shift particles leaving the supercell
 *
 * The functor fulfills the restriction that all frames except the last
 * must be fully filled with particles as can be stored in a frame.
 *
 * @tparam T_numWorkers number of workers
 */
template< uint32_t T_numWorkers >
struct KernelShiftParticles
{
    /** This kernel moves particles to the next supercell
     *
     * @warning this kernel can only run with a double checker board
     */
    template<
        typename T_ParBox,
        typename Mapping,
        typename T_Acc
    >
    DINLINE void operator()(
        T_Acc const & acc,
        T_ParBox pb,
        Mapping mapper
    ) const
    {
        using ParBox = T_ParBox;
        using FrameType = typename ParBox::FrameType;
        using FramePtr = typename ParBox::FramePtr;

        PMACC_CONSTEXPR_CAPTURE uint32_t dim = Mapping::Dim;
        constexpr uint32_t frameSize = math::CT::volume< typename FrameType::SuperCellSize >::type::value;
        /* number exchanges in 2D=9 and in 3D=27 */
        constexpr uint32_t numExchanges = traits::NumberOfExchanges< dim >::value;
        constexpr uint32_t numWorkers = T_numWorkers;

        /* define memory for two times Exchanges
         * index range [0,numExchanges-1] are being referred to as `low frames`
         * index range [numExchanges,2*numExchanges-1] are being referred to as `high frames`
         */
        PMACC_SMEM(
            acc,
            destFrames,
            memory::Array<
                FramePtr,
                numExchanges * 2
            >
        );
        //count particles per frame
        PMACC_SMEM(
            acc,
            destFramesCounter,
            memory::Array<
                int,
                numExchanges
            >
        );

        PMACC_SMEM(
            acc,
            frame,
            FramePtr
        );
        PMACC_SMEM(
            acc,
            mustShift,
            bool
        );

        DataSpace< dim > superCellIdx = mapper.getSuperCellIndex( DataSpace< dim >( blockIdx ) );
        uint32_t const workerIdx = threadIdx.x;

        using namespace mappings::threads;

        ForEachIdx<
            IdxConfig<
                1,
                numWorkers
            >
        >{ workerIdx }(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                mustShift = pb.getSuperCell( superCellIdx ).mustShift( );
                if ( mustShift )
                {
                    pb.getSuperCell( superCellIdx ).setMustShift( false );
                    frame = pb.getFirstFrame( superCellIdx );
                }
            }
        );

        __syncthreads( );
        if ( !mustShift || !frame.isValid( ) ) return;

        using ExchangeDomCfg = IdxConfig<
            numExchanges,
            numWorkers
        >;

        memory::CtxArray<
            int,
            ExchangeDomCfg
        > newParticleInFrame( 0 );

        memory::CtxArray<
            DataSpace< dim >,
            ExchangeDomCfg
        > relativeCtx(
            workerIdx,
            [&](
                uint32_t const linearIdx,
                uint32_t const
            )
            -> DataSpace< dim >
            {
                return superCellIdx + Mask::getRelativeDirections< dim > ( linearIdx + 1);
            }
        );

        ForEachIdx< ExchangeDomCfg > forEachExchange( workerIdx );

        /* if a partially filled last frame exists for the neighboring supercell,
         * each master thread (one master per direction) will load it
         */
        forEachExchange(
            [&](
                uint32_t const linearIdx,
                uint32_t const idx
            )
            {
                destFramesCounter[ linearIdx ] = 0;
                destFrames[ linearIdx ] = FramePtr();
                destFrames[ linearIdx + numExchanges ] = FramePtr();
                /* load last frame of neighboring supercell */
                FramePtr tmpFrame( pb.getLastFrame( relativeCtx[ idx ] ) );

                if ( tmpFrame.isValid() )
                {
                    uint32_t particlesInFrame = pb.getSuperCell( relativeCtx[ idx ] ).getSizeLastFrame( );
                    // do not use the neighbor's last frame if it is full
                    if ( particlesInFrame < frameSize )
                    {
                        newParticleInFrame[ idx ] = -particlesInFrame;
                        destFrames[ linearIdx ] = tmpFrame;
                        destFramesCounter[ linearIdx ] = particlesInFrame;
                    }
                }
            }
        );

        __syncthreads( );

        /* iterate over the frame list of the current supercell */
        while ( frame.isValid( ) )
        {
            using ParticleDomCfg = IdxConfig<
                frameSize,
                numWorkers
            >;

            ForEachIdx< ParticleDomCfg > forEachParticle( workerIdx );

            memory::CtxArray<
                lcellId_t,
                ParticleDomCfg
            > destParticleIdxCtx( INV_LOC_IDX );
            memory::CtxArray<
                int,
                ParticleDomCfg
            > directionCtx;

            forEachParticle(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const idx
                )
                {
                    /* set to value to of multiMask to a value in range [-2, EXCHANGES - 1]
                     * -2 is no particle
                     * -1 is particle but it is not shifted (stays in supercell)
                     * >=0 particle moves in a certain direction
                     *     (@see ExchangeType in types.h)
                     */
                    directionCtx[ idx ] = frame[ linearIdx ][ multiMask_ ] - 2;
                    if ( directionCtx[ idx ] >= 0 )
                    {
                        destParticleIdxCtx[ idx ] = atomicAdd( &(destFramesCounter[ directionCtx[ idx ] ]), 1, ::alpaka::hierarchy::Threads{} );
                    }
                }
            );
            __syncthreads( );

            forEachExchange(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const idx
                )
                {
                    /* If the master thread (responsible for a certain direction) did not
                     * obtain a `low frame` from the neighboring super cell before the loop,
                     * it will create one now.
                     *
                     * In case not all particles that are shifted to the neighboring
                     * supercell fit into the `low frame`, a second frame is created to
                     * contain further particles, the `high frame` (default: invalid).
                     */
                    if ( destFramesCounter[ linearIdx ] > 0 )
                    {
                        /* if we had no `low frame` we load a new empty one */
                        if ( !destFrames[ linearIdx ].isValid( ) )
                        {
                            FramePtr tmpFrame( pb.getEmptyFrame( ) );
                            destFrames[ linearIdx ] = tmpFrame;
                            pb.setAsLastFrame(
                                acc,
                                tmpFrame,
                                relativeCtx[ idx ]
                            );
                        }
                        /* check if a `high frame` is needed */
                        if ( destFramesCounter[ linearIdx ] > frameSize )
                        {
                            FramePtr tmpFrame( pb.getEmptyFrame( ) );
                            destFrames[ linearIdx + numExchanges ] = tmpFrame;
                            pb.setAsLastFrame(
                                acc,
                                tmpFrame,
                                relativeCtx[ idx ]
                            );
                        }
                    }
                }
            );
            __syncthreads( );

            forEachParticle(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const idx
                )
                {
                    /* All threads with a valid index in the neighbor's frame, valid index
                     * range is [0, frameSize * 2-1], will copy their particle to the new
                     * frame.
                     *
                     * The default value for indexes (in the destination frame) is
                     * above this range (INV_LOC_IDX) for all particles that are not shifted.
                     */
                    if ( destParticleIdxCtx[ idx ] < frameSize * 2 )
                    {
                        if ( destParticleIdxCtx[ idx ] >= frameSize )
                        {
                            /* use `high frame` */
                            directionCtx[ idx ] += numExchanges;
                            destParticleIdxCtx[ idx ] -= frameSize;
                        }
                        auto dstParticle = destFrames[ directionCtx[ idx ] ][ destParticleIdxCtx[ idx ] ];
                        auto srcParticle = frame[ linearIdx ];
                        dstParticle[ multiMask_ ] = 1;
                        srcParticle[ multiMask_ ] = 0;
                        auto dstFilteredParticle =
                            particles::operations::deselect< multiMask >( dstParticle );
                        particles::operations::assign(
                            dstFilteredParticle,
                            srcParticle
                        );
                    }
                }
            );
            __syncthreads( );

            forEachExchange(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const idx
                )
                {
                    /* if the `low frame` is full, each master thread
                     * uses the `high frame` (is invalid, if still empty) as the next
                     * `low frame` for the following iteration of the loop
                     */
                    if ( destFramesCounter[ linearIdx ] >= frameSize )
                    {
                        newParticleInFrame[ idx ] += frameSize;
                        destFramesCounter[ linearIdx ] -= frameSize;
                        destFrames[ linearIdx ] = destFrames[ linearIdx + numExchanges ];
                        destFrames[ linearIdx + numExchanges ] = FramePtr( );
                    }
                    if ( linearIdx == 0 )
                    {
                        frame = pb.getNextFrame( frame );
                    }
                }
            );
            __syncthreads( );
        }

        forEachExchange(
            [&](
                uint32_t const linearIdx,
                uint32_t const idx
            )
            {
                newParticleInFrame[ idx ] += destFramesCounter[ linearIdx ];
                if( newParticleInFrame[ idx ] > 0 )
                {
                    /* Each master thread updates the number of particles
                     * for the neighbor frame. The number of particles in the neighbor
                     * frame must be correct because fill gaps is only called on the
                     * current used supercell.
                     */
                    auto & superCell = pb.getSuperCell( relativeCtx[ idx ] );
                    superCell.setNumParticles(
                        superCell.getNumParticles() + newParticleInFrame[ idx ]
                    );
                }
            }
        );

        // fill all gaps in the frame list of the supercell
        KernelFillGaps< numWorkers >{ }(
            acc,
            pb,
            mapper
        );
    }
};

/** deletes all particles within an AREA
 *
 * @tparam T_numWorkers number of workers
 */
template< uint32_t T_numWorkers >
struct KernelDeleteParticles
{
    /** deletes all particles
     *
     * @warning the particle memory of the particle is not byte-wise zeroed
     *
     * @tparam T_ParticleBox pmacc::ParticlesBox, particle box type
     * @tparam T_Mapping mapper functor type
     *
     * @param pb particle memory
     * @param mapper functor to map a block to a supercell
     */
    template<
        typename T_ParticleBox,
        typename T_Mapping,
        typename T_Acc
    >
    DINLINE void operator()(
        T_Acc const & acc,
        T_ParticleBox pb,
        T_Mapping const mapper
    ) const
    {
        using namespace particles::operations;
        using namespace mappings::threads;

        using ParticleBox = T_ParticleBox;
        using FrameType = typename ParticleBox::FrameType;
        using FramePtr = typename ParticleBox::FramePtr;

        constexpr uint32_t dim = T_Mapping::Dim;
        constexpr uint32_t frameSize = math::CT::volume< typename FrameType::SuperCellSize >::type::value;
        constexpr uint32_t numWorkers = T_numWorkers;

        DataSpace< dim > const superCellIdx = mapper.getSuperCellIndex( DataSpace< dim >( blockIdx ) );
        uint32_t const workerIdx = threadIdx.x;

        PMACC_SMEM(
            acc,
            frame,
            FramePtr
        );

        ForEachIdx<
            IdxConfig<
                1,
                numWorkers
            >
        > onlyMaster{ workerIdx };

        onlyMaster(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                frame = pb.getLastFrame( superCellIdx );
            }
        );

        __syncthreads( );

        while( frame.isValid( ) )
        {
            using ParticleDomCfg = IdxConfig<
                frameSize,
                numWorkers
            >;
            // loop over all particles in the frame
            ForEachIdx< ParticleDomCfg > forEachParticle( workerIdx );

            forEachParticle(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const
                )
                {
                    auto particle = ( frame[ linearIdx ] );
                    particle[ multiMask_ ] = 0; // delete particle
                }
            );

            __syncthreads( );

            onlyMaster(
                [&](
                    uint32_t const,
                    uint32_t const
                )
                {
                    // always remove the last frame
                    frame = getPreviousFrameAndRemoveLastFrame(
                        frame,
                        pb,
                        superCellIdx
                    );
                }
            );
            __syncthreads( );
        }

        onlyMaster(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                // all frames and particles are removed
                pb.getSuperCell( superCellIdx ).setNumParticles( 0 );
            }
        );
    }
};

/** copy particles from the guard to an exchange buffer
 *
 * @warning This kernel resets the number of particles in the processed supercells even
 * if there are particles left in the supercell and does not guarantee that the last frame is
 * contiguous filled.
 * Call KernelFillGaps afterwards if you need a valid number of particles
 * and a contiguously filled last frame.
 *
 * @tparam T_numWorkers number of workers
 */
template< uint32_t T_numWorkers >
struct KernelCopyGuardToExchange
{
    /** copy guard particles to an exchange buffer
     *
     * @tparam T_ParBox pmacc::ParticlesBox, particle box type
     * @tparam T_ExchangeValueType frame type of the exchange buffer
     * @tparam T_Mapping mapper functor type
     *
     * @param pb particle memory
     * @param exchangeBox exchange buffer for particles
     * @param mapper functor to map a block to a supercell
     */
    template<
        typename T_ParBox,
        typename T_ExchangeValueType,
        typename T_Mapping,
        typename T_Acc
    >
    DINLINE void operator()(
        T_Acc const & acc,
        T_ParBox pb,
        ExchangePushDataBox<
            vint_t,
            T_ExchangeValueType,
            T_Mapping::Dim - 1
        > exchangeBox,
        T_Mapping const mapper
    ) const
    {
        using namespace particles::operations;
        using namespace mappings::threads;

        PMACC_CONSTEXPR_CAPTURE uint32_t dim = T_Mapping::Dim;
        constexpr uint32_t frameSize = math::CT::volume< typename T_ParBox::FrameType::SuperCellSize >::type::value;
        constexpr uint32_t numWorkers = T_numWorkers;

        using FramePtr = typename T_ParBox::FramePtr;

        DataSpace< dim > const superCellIdx = mapper.getSuperCellIndex( DataSpace< dim >( blockIdx ) );
        uint32_t const workerIdx = threadIdx.x;

        // number of particles in the current handled frame
        PMACC_SMEM(
            acc,
            numParticles,
            int
        );
        PMACC_SMEM(
            acc,
            frame,
            FramePtr
        );

        /* `exchangeChunk` is a view to a chunk of the memory in the exchange-
         * The chunk contains between 0 and `numParticles` particles
         * and is updated for each frame.
         */
        PMACC_SMEM(
            acc,
            exchangeChunk,
            TileDataBox< T_ExchangeValueType >
        );

        /* flag: define if all particles from the current frame are copied to the
         * exchange buffer
         *
         * `true` if all particles are copied, else `false`
         */
        PMACC_SMEM(
            acc,
            allParticlesCopied,
            bool
        );

        ForEachIdx<
            IdxConfig<
                1,
                numWorkers
            >
        > onlyMaster{ workerIdx };

        onlyMaster(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                allParticlesCopied = true;
                frame = pb.getLastFrame( superCellIdx );
            }
        );

        __syncthreads( );

        while ( frame.isValid( ) && allParticlesCopied )
        {
            using ParticleDomCfg = IdxConfig<
                frameSize,
                numWorkers
            >;

            /* the index of the gap in the exchange box where the particle
             * is copied to
             */
            memory::CtxArray<
                lcellId_t,
                ParticleDomCfg
            >
            exchangeGapIdxCtx( INV_LOC_IDX );

            onlyMaster(
                [&](
                    uint32_t const,
                    uint32_t const
                )
                {
                    numParticles = 0;
                }
            );

            __syncthreads( );

             // loop over all particles in the frame
            ForEachIdx< ParticleDomCfg > forEachParticle( workerIdx );

            forEachParticle(
                [&](
                    uint32_t const linearIdx,
                    uint32_t const idx
                )
                {
                    if ( frame[ linearIdx ][ multiMask_ ] == 1 )
                    {
                        exchangeGapIdxCtx[ idx ] = nvidia::atomicAllInc( acc, &numParticles, ::alpaka::hierarchy::Threads{} );
                    }
                }
            );
            __syncthreads( );

            if( numParticles > 0 )
            {

                onlyMaster(
                    [&](
                        uint32_t const,
                        uint32_t const
                    )
                    {
                        // try to get as many memory as particles in the current frame
                        exchangeChunk = exchangeBox.pushN(
                            acc,
                            numParticles,
                            // Compute the target supercell depending on the exchangeType
                            DataSpaceOperations< dim >::reduce(
                                superCellIdx,
                                mapper.getExchangeType( )
                            ),
                            ::alpaka::hierarchy::Blocks{}
                        );
                        if( exchangeChunk.getSize( ) < numParticles )
                            allParticlesCopied = false;
                    }
                );

                __syncthreads( );

                forEachParticle(
                    [&](
                        uint32_t const linearIdx,
                        uint32_t const idx
                    )
                    {
                        if( exchangeGapIdxCtx[ idx ] != INV_LOC_IDX && exchangeGapIdxCtx[ idx ] < exchangeChunk.getSize( ) )
                        {
                            auto parDest = exchangeChunk[ exchangeGapIdxCtx[ idx ] ][ 0 ];
                            auto parSrc = frame[ linearIdx ];
                            assign( parDest, parSrc );
                            parSrc[ multiMask_ ] = 0;
                        }
                    }
                );
                __syncthreads( );
            }

            onlyMaster(
                [&](
                    uint32_t const,
                    uint32_t const
                )
                {
                    /* do not remove the frame if we had not copied
                     * all particles from the current frame to the exchange buffer
                     */
                    if ( allParticlesCopied )
                        frame = getPreviousFrameAndRemoveLastFrame( frame, pb, superCellIdx );
                }
            );

            __syncthreads( );
        }
        onlyMaster(
            [&](
                uint32_t const,
                uint32_t const
            )
            {
                /* Mark supercell as empty even if there are particles left.
                 * This kernel not depends on the correct number particles in the supercell.
                 */
                pb.getSuperCell( superCellIdx ).setNumParticles( 0 );
            }
        );

    }
};

/** copy particles from exchange buffer into the border of the simulation
 *
 * @tparam T_numWorkers number of workers
 */
template< uint32_t T_numWorkers >
struct KernelInsertParticles
{
    /** copy particles from exchange buffer into the border of the simulation
     *
     * @tparam T_ParBox pmacc::ParticlesBox, particle box type
     * @tparam T_ExchangeValueType frame type of the exchange buffer
     * @tparam T_Mapping mapper functor type
     *
     * @param pb particle memory
     * @param exchangeBox exchange box for particles
     * @param mapper functor to map a block to a supercell
     */
    template<
        typename T_ParBox,
        typename T_ExchangeValueType,
        typename T_Mapping,
        typename T_Acc
    >
    DINLINE void operator()(
        T_Acc const & acc,
        T_ParBox pb,
        ExchangePopDataBox<
            vint_t,
            T_ExchangeValueType,
            T_Mapping::Dim - 1
        > exchangeBox,
        T_Mapping const mapper
    ) const
    {
        using namespace particles::operations;
        using namespace mappings::threads;

        PMACC_CONSTEXPR_CAPTURE uint32_t dim = T_Mapping::Dim;
        constexpr uint32_t frameSize = math::CT::volume< typename T_ParBox::FrameType::SuperCellSize >::type::value;
        constexpr uint32_t numWorkers = T_numWorkers;

        uint32_t const workerIdx = threadIdx.x;

        using FramePtr = typename T_ParBox::FramePtr;

        PMACC_SMEM(
            acc,
            frame,
            FramePtr
        );
        PMACC_SMEM(
            acc,
            elementCount,
            int
        );
        PMACC_SMEM(
            acc,
            exchangeChunk,
            TileDataBox< T_ExchangeValueType >
        );

        using MasterOnly = IdxConfig<
            1,
            numWorkers
        >;

        /* compressed index of the the supercell
         * can be uncompressed with `DataSpaceOperations< >::extend()`
         */
        memory::CtxArray<
            DataSpace< dim - 1 >,
            MasterOnly
        > compressedSuperCellIdxCtx{ };

        ForEachIdx<
            MasterOnly
        > onlyMaster{ workerIdx };

        onlyMaster(
            [&](
                uint32_t const,
                uint32_t const idx
            )
            {
                exchangeChunk = exchangeBox.get(
                    blockIdx.x,
                    compressedSuperCellIdxCtx[ idx ]
                );
                elementCount = exchangeChunk.getSize( );
                if ( elementCount > 0 )
                {
                    frame = pb.getEmptyFrame( );
                }
            }
        );

        __syncthreads( );

        // loop over all particles in the frame
        ForEachIdx<
            IdxConfig<
                frameSize,
                numWorkers
            >
        > forEachParticle{ workerIdx };

        forEachParticle(
            [&](
                uint32_t const linearIdx,
                uint32_t const
            )
            {
                if( linearIdx < elementCount )
                {
                    auto parDestFull = frame[ linearIdx ];
                    parDestFull[ multiMask_ ] = 1;
                    auto parSrc = exchangeChunk[ linearIdx ][ 0 ];
                    /*we know that source has no multiMask*/
                    auto parDest = deselect<multiMask>( parDestFull );
                    assign( parDest, parSrc );
                }
            }
        );

        /** @bug This synchronize fixes a kernel crash in special cases,
         * psychocoderHPC: I can't tell why.
         */
        __syncthreads( );

        onlyMaster(
            [&](
                uint32_t const,
                uint32_t const idx
            )
            {
                if( elementCount > 0 )
                {
                    // compute the super cell position in target frame to insert into
                    //! @todo: offset == simulation border should be passed to this func instead of being created here
                    DataSpace< dim > dstSuperCell = DataSpaceOperations < dim - 1 > ::extend(
                        compressedSuperCellIdxCtx[ idx ],
                        mapper.getExchangeType( ),
                        mapper.getGridSuperCells( ),
                        mapper.getGuardingSuperCells( )
                    );

                    pb.setAsLastFrame(
                        acc,
                        frame,
                        dstSuperCell
                    );
                }
            }
        );

    }
};

} //namespace pmacc
