/**
 * Copyright 2013-2015 Axel Huebl, Rene Widera, Marco Garten
 *
 * This file is part of PIConGPU.
 *
 * PIConGPU is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * PIConGPU is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with PIConGPU.
 * If not, see <http://www.gnu.org/licenses/>.
 */



#pragma once

#include "types.h"
#include "particles/frame_types.hpp"
#include "basicOperations.hpp"

#include "simulation_defines.hpp"

#include "FieldTmp.hpp"
#include "particles/memory/boxes/ParticlesBox.hpp"

#include "memory/boxes/CachedBox.hpp"
#include "dimensions/DataSpaceOperations.hpp"
#include "nvidia/functors/Add.hpp"
#include "mappings/threads/ThreadCollective.hpp"
#include "algorithms/Set.hpp"

#include "particles/frame_types.hpp"

namespace picongpu
{
    using namespace PMacc;


    template<class BlockDescription_, uint32_t AREA, class TmpBox, class ParBox, class FrameSolver, class Mapping>
    __global__ void kernelComputeSupercells( TmpBox fieldTmp, ParBox boxPar, FrameSolver frameSolver, Mapping mapper )
    {

        typedef typename BlockDescription_::SuperCellSize SuperCellSize;
        const DataSpace<simDim> block( mapper.getSuperCellIndex( DataSpace<simDim > ( blockIdx ) ) );


        const DataSpace<simDim > threadIndex( threadIdx );
        const int linearThreadIdx = DataSpaceOperations<simDim>::template map<SuperCellSize > ( threadIndex );

        __shared__ typename ParBox::FrameType *frame;
        __shared__ bool isValid;
        __shared__ lcellId_t particlesInSuperCell;


        if( linearThreadIdx == 0 )
        {
            frame = &( boxPar.getLastFrame( block, isValid ) );
            particlesInSuperCell = boxPar.getSuperCell( block ).getSizeLastFrame( );
        }
        __syncthreads( );

        if( !isValid )
            return; //end kernel if we have no frames

        PMACC_AUTO( cachedVal, CachedBox::create < 0, typename TmpBox::ValueType > ( BlockDescription_( ) ) );
        Set<typename TmpBox::ValueType > set( float_X( 0.0 ) );

        ThreadCollective<BlockDescription_> collective( linearThreadIdx );
        collective( set, cachedVal );

        __syncthreads( );
        while( isValid )
        {
            if( linearThreadIdx < particlesInSuperCell )
            {
                frameSolver( *frame, linearThreadIdx, SuperCellSize::toRT(), cachedVal );
            }
            __syncthreads( );
            if( linearThreadIdx == 0 )
            {
                frame = &( boxPar.getPreviousFrame( *frame, isValid ) );
                particlesInSuperCell = PMacc::math::CT::volume<SuperCellSize>::type::value;
            }
            __syncthreads( );
        }

        nvidia::functors::Add add;
        const DataSpace<simDim> blockCell = block * MappingDesc::SuperCellSize::toRT( );
        PMACC_AUTO( fieldTmpBlock, fieldTmp.shift( blockCell ) );
        collective( add, fieldTmpBlock, cachedVal );
        __syncthreads( );
    }

    template<class Box, class Mapping>
    __global__ void kernelBashValue( Box fieldTmp,
                                     Box targetJ,
                                     DataSpace<simDim> exchangeSize,
                                     DataSpace<simDim> direction,
                                     Mapping mapper )
    {
        const DataSpace<Mapping::Dim> threadIndex(threadIdx);
        const DataSpace<simDim> blockCell(
                                           mapper.getSuperCellIndex( DataSpace<simDim > ( blockIdx ) )
                                           * Mapping::SuperCellSize::toRT( )
                                           );
        const DataSpace<Mapping::Dim> sourceCell( blockCell + threadIndex );

        /*origin in area from local GPU*/
        DataSpace<simDim> nullSourceCell(
                                          mapper.getSuperCellIndex( DataSpace<simDim > ( ) )
                                          * Mapping::SuperCellSize::toRT( )
                                          );
        DataSpace<simDim> targetCell( sourceCell - nullSourceCell );

        for (uint32_t d = 0; d < simDim; ++d)
        {
            if( direction[d] == -1 )
            {
                if( threadIndex[d] < SuperCellSize::toRT()[d] - exchangeSize[d] ) return;
                targetCell[d] -= SuperCellSize::toRT()[d] - exchangeSize[d];
            }
            else if( ( direction[d] == 1 ) && ( threadIndex[d] >= exchangeSize[d] ) ) return;
        }
        targetJ( targetCell ) = fieldTmp( sourceCell );
    }

    template<class Box, class Mapping>
    __global__ void kernelInsertValue( Box fieldTmp,
                                       Box sourceTmp,
                                       DataSpace<simDim> exchangeSize,
                                       DataSpace<simDim> direction,
                                       Mapping mapper )
    {
        const DataSpace<Mapping::Dim> threadIndex(threadIdx);
        const DataSpace<simDim> blockCell(
                                           mapper.getSuperCellIndex( DataSpace<simDim > ( blockIdx ) )
                                           * Mapping::SuperCellSize::toRT( )
                                           );
        DataSpace<Mapping::Dim> targetCell( blockCell + threadIndex );

        /*origin in area from local GPU*/
        DataSpace<simDim> nullSourceCell(
                                          mapper.getSuperCellIndex( DataSpace<simDim > ( ) )
                                          * Mapping::SuperCellSize::toRT( )
                                          );
        DataSpace<simDim> sourceCell( targetCell - nullSourceCell );

        for (uint32_t d = 0; d < simDim; ++d)
        {
            if( direction[d] == 1 )
            {
                if( threadIndex[d] < SuperCellSize::toRT()[d] - exchangeSize[d] ) return;
                sourceCell[d] -= SuperCellSize::toRT()[d] - exchangeSize[d];
                targetCell[d] -= SuperCellSize::toRT()[d];
            }
            else if( direction[d] == -1 )
            {
                if( threadIndex[d] >= exchangeSize[d] ) return;
                targetCell[d] += SuperCellSize::toRT()[d];
            }
        }

        fieldTmp( targetCell ) += sourceTmp( sourceCell );
    }

} // namespace picongpu
