/**
 * Copyright 2013 Axel Huebl, Heiko Burau, Ren√© Widera
 *
 * This file is part of PIConGPU. 
 * 
 * PIConGPU is free software: you can redistribute it and/or modify 
 * it under the terms of the GNU General Public License as published by 
 * the Free Software Foundation, either version 3 of the License, or 
 * (at your option) any later version. 
 * 
 * PIConGPU is distributed in the hope that it will be useful, 
 * but WITHOUT ANY WARRANTY; without even the implied warranty of 
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the 
 * GNU General Public License for more details. 
 * 
 * You should have received a copy of the GNU General Public License 
 * along with PIConGPU.  
 * If not, see <http://www.gnu.org/licenses/>. 
 */

#ifndef FIELDJ_KERNEL
#define	FIELDJ_KERNEL

#include "types.h"
#include "particles/frame_types.hpp"
#include "basicOperations.hpp"

#include "simulation_defines.hpp"

#include "FieldJ.hpp"
#include "particles/memory/boxes/ParticlesBox.hpp"


#include "algorithms/Velocity.hpp"

#include "memory/boxes/CachedBox.hpp"
#include "dimensions/DataSpaceOperations.hpp"
#include "nvidia/functors/Add.hpp"
#include "mappings/threads/ThreadCollective.hpp"
#include "algorithms/Set.hpp"

#include "particles/frame_types.hpp"

namespace picongpu
{

using namespace PMacc;




typedef FieldJ::FloatJ FloatJ;
typedef typename FieldJ::DataBoxType J_DataBox;

template<int workerMultiplier, class BlockDescription_, uint32_t AREA, class JBox, class ParBox, class Mapping, class FrameSolver>
__global__ void kernelComputeCurrent(JBox fieldJ,
                                     ParBox boxPar, FrameSolver frameSolver, Mapping mapper)
{
    typedef typename ParBox::FrameType FrameType;
    typedef typename Mapping::SuperCellSize SuperCellSize;

    const uint32_t cellsPerSuperCell = SuperCellSize::elements;

    const DataSpace<simDim> block(mapper.getSuperCellIndex(DataSpace<simDim > (blockIdx)));
    const DataSpace<simDim > threadIndex(threadIdx);

    /* thread id, can be greater than cellsPerSuperCell*/
    const int linearThreadIdx = DataSpaceOperations<simDim>::template map<SuperCellSize > (threadIndex);
        
    const uint32_t virtualBlockId = linearThreadIdx / cellsPerSuperCell;
    /* move linearThreadIdx for all threads to [0;cellsPerSuperCell) */
    const int virtualLinearId = linearThreadIdx-(virtualBlockId * cellsPerSuperCell);


    __shared__ FrameType * frame[workerMultiplier];
    __shared__ bool isValid[workerMultiplier];
    __shared__ lcellId_t particlesInSuperCell;

    __syncthreads(); /*wait that all shared memory is initialised*/

    if (linearThreadIdx == 0)
    {
        frame[0] = &(boxPar.getLastFrame(block, isValid[0]));
        particlesInSuperCell = boxPar.getSuperCell(block).getSizeLastFrame();
        /* Set all isValid flags with id >0 to false.
         * isValid[0] is already initialized!!
         * Read valid frames.
         */
        for (int i = 1; i < workerMultiplier; ++i)
        {
            isValid[i] = false;
            if (isValid[i - 1])
                frame[i] = &(boxPar.getPreviousFrame(*(frame[i - 1]), isValid[i]));
        }
    }
    __syncthreads();

    /* only leave calculation if we have no frames
     * If we have a frame than we need all threads for
     * filling shared memory
     */
    if (!(isValid[0]))
        return;

    PMACC_AUTO(cachedJ, CachedBox::create < 0, typename JBox::ValueType > (BlockDescription_()));

    Set<typename JBox::ValueType > set(float3_X(0.0, 0.0, 0.0));
    ThreadCollective<BlockDescription_, cellsPerSuperCell * workerMultiplier> collectivSet(linearThreadIdx);
    collectivSet(set, cachedJ);

    /* now all threads can leave if they have no frame */
    if (!(isValid[virtualBlockId]))
        return;
    
    __syncthreads();
    /* all threads can check isValid[0] because we know that
     * we are at end of frame list if isValid[0] is not valid
     */
    while (isValid[virtualBlockId])
    {
        /* virtualBlockId != 0 no need to check particlesInSuperCell 
         * because only last frame is not full filled
         */
        if (virtualBlockId != 0 || linearThreadIdx < particlesInSuperCell)
        {
            frameSolver(*(frame[virtualBlockId]),
                        virtualLinearId,
                        cachedJ);
        }
        __syncthreads();
        if (linearThreadIdx == 0)
        {
            particlesInSuperCell = SuperCellSize::elements;
            isValid[0] = isValid[workerMultiplier - 1];
            if (isValid[workerMultiplier - 1])
                frame[0] = &(boxPar.getPreviousFrame(*(frame[workerMultiplier - 1]), isValid[0]));
            /* read all frames in sequential order*/
            for (int i = 1; i < workerMultiplier; ++i)
            {
                isValid[i] = false;
                if (isValid[i - 1])
                    frame[i] = &(boxPar.getPreviousFrame(*(frame[i - 1]), isValid[i]));
            }
        }
        __syncthreads();
    }
    /* we wait that all threads finush the loop*/
    __syncthreads();
    /*now we can write to global memory with all threads*/
    nvidia::functors::Add add;
    const DataSpace<simDim> blockCell = block * SuperCellSize::getDataSpace();
    ThreadCollective<BlockDescription_,cellsPerSuperCell * workerMultiplier> collectivAdd(linearThreadIdx);
    PMACC_AUTO(fieldJBlock, fieldJ.shift(blockCell));
    collectivAdd(add, fieldJBlock, cachedJ);
    __syncthreads();
}

template<class ParticleAlgo, class Velocity, class TVec>
struct ComputeCurrentPerFrame
{

    HDINLINE ComputeCurrentPerFrame(const float3_X cellSize, const float_X deltaTime) :
    cellSize(cellSize), deltaTime(deltaTime)
    {
    }

    template<class FrameType, class BoxJ >
    DINLINE void operator()(FrameType& frame, const int localIdx, BoxJ & jBox)
    {

        typedef typename FrameType::PosType PosType;
        typedef typename FrameType::MomType MomType;
        typedef typename FrameType::MassType MassType;

        typedef typename FrameType::WeightingType WeightingType;

        typedef float_X WeightingType;
        typedef typename FrameType::ChargeType ChargeType;

        const WeightingType weighting = frame.getWeighting()[localIdx];
        const PosType pos = frame.getPosition()[localIdx];
        const int particleCellIdx = frame.getCellIdx()[localIdx];
        const ChargeType charge = frame.getCharge(weighting);
        const DataSpace<TVec::dim> localCell(DataSpaceOperations<TVec::dim>::template map<TVec > (particleCellIdx));

        Velocity velocity;
        const float3_X vel = velocity(
                                      frame.getMomentum()[localIdx],
                                      frame.getMass(weighting));
        PMACC_AUTO(fieldJShiftToParticle, jBox.shift(localCell));
        ParticleAlgo perParticle;
        perParticle(fieldJShiftToParticle,
                    pos,
                    vel,
                    charge,
                    cellSize,
                    deltaTime
                    );
    }

private:
    const PMACC_ALIGN(cellSize, float3_X);
    const PMACC_ALIGN(deltaTime, float);
};

template<class Mapping>
__global__ void kernelAddCurrentToE(typename FieldE::DataBoxType fieldE,
                                    J_DataBox fieldJ,
                                    Mapping mapper)
{

    const DataSpace<simDim> blockCell(
                                      mapper.getSuperCellIndex(DataSpace<simDim > (blockIdx))
                                      * Mapping::SuperCellSize::getDataSpace()
                                      );
    const DataSpace<Mapping::Dim> cell(blockCell + DataSpace<simDim > (threadIdx));

    // Amperes Law:
    //   Change of the dE = - j / EPS0 * dt
    //                        j = current density (= current per area)
    //                          = fieldJ
    const float_X deltaT = DELTA_T;
    fieldE(cell) -= fieldJ(cell) * (float_X(1.0) / EPS0) * deltaT;
}

template<class Mapping>
__global__ void kernelBashCurrent(J_DataBox fieldJ,
                                  J_DataBox targetJ,
                                  DataSpace<simDim> exchangeSize,
                                  DataSpace<simDim> direction,
                                  Mapping mapper)
{
    const DataSpace<simDim> blockCell(
                                      mapper.getSuperCellIndex(DataSpace<simDim > (blockIdx))
                                      * Mapping::SuperCellSize::getDataSpace()
                                      );
    const DataSpace<Mapping::Dim> sourceCell(blockCell + DataSpace<simDim > (threadIdx));

    /*origin in area from local GPU*/
    DataSpace<simDim> nullSourceCell(
                                     mapper.getSuperCellIndex(DataSpace<simDim > ())
                                     * Mapping::SuperCellSize::getDataSpace()
                                     );
    DataSpace<simDim> targetCell(sourceCell - nullSourceCell);

    if (direction.x() == -1)
    {
        if (threadIdx.x < TILE_WIDTH - exchangeSize.x()) return;
        targetCell.x() -= TILE_WIDTH - exchangeSize.x();
    }
    else if ((direction.x() == 1) && (threadIdx.x >= exchangeSize.x())) return;
    if (direction.y() == -1)
    {
        if (threadIdx.y < TILE_HEIGHT - exchangeSize.y()) return;
        targetCell.y() -= TILE_HEIGHT - exchangeSize.y();
    }
    else if ((direction.y() == 1) && (threadIdx.y >= exchangeSize.y())) return;

    if (direction.z() == -1)
    {
        if (threadIdx.z < TILE_DEPTH - exchangeSize.z()) return;
        targetCell.z() -= TILE_DEPTH - exchangeSize.z();
    }
    else

        if ((direction.z() == 1) && (threadIdx.z >= exchangeSize.z())) return;

    targetJ(targetCell) = fieldJ(sourceCell);
}

template<class Mapping>
__global__ void kernelInsertCurrent(J_DataBox fieldJ,
                                    J_DataBox sourceJ,
                                    DataSpace<simDim> exchangeSize,
                                    DataSpace<simDim> direction,
                                    Mapping mapper)
{
    const DataSpace<simDim> blockCell(
                                      mapper.getSuperCellIndex(DataSpace<simDim > (blockIdx))
                                      * Mapping::SuperCellSize::getDataSpace()
                                      );
    DataSpace<Mapping::Dim> targetCell(blockCell + DataSpace<simDim > (threadIdx));

    /*origin in area from local GPU*/
    DataSpace<simDim> nullSourceCell(
                                     mapper.getSuperCellIndex(DataSpace<simDim > ())
                                     * Mapping::SuperCellSize::getDataSpace()
                                     );
    DataSpace<simDim> sourceCell(targetCell - nullSourceCell);

    if (direction.x() == 1)
    {
        if (threadIdx.x < TILE_WIDTH - exchangeSize.x()) return;
        sourceCell.x() -= TILE_WIDTH - exchangeSize.x();
        targetCell.x() -= TILE_WIDTH;
    }
    else if (direction.x() == -1)
    {
        if (threadIdx.x >= exchangeSize.x()) return;
        targetCell.x() += TILE_WIDTH;
    }
    if (direction.y() == 1)
    {
        if (threadIdx.y < TILE_HEIGHT - exchangeSize.y()) return;
        sourceCell.y() -= TILE_HEIGHT - exchangeSize.y();
        targetCell.y() -= TILE_HEIGHT;
    }
    else if (direction.y() == -1)
    {
        if (threadIdx.y >= exchangeSize.y()) return;
        targetCell.y() += TILE_HEIGHT;
    }

    if (direction.z() == 1)
    {
        if (threadIdx.z < TILE_DEPTH - exchangeSize.z()) return;
        sourceCell.z() -= TILE_DEPTH - exchangeSize.z();
        targetCell.z() -= TILE_DEPTH;
    }
    else if (direction.z() == -1)
    {
        if (threadIdx.z >= exchangeSize.z()) return;
        targetCell.z() += TILE_DEPTH;
    }

    fieldJ(targetCell) += sourceJ(sourceCell);
}

}


#endif  //end FIELDJ_KERNEL
