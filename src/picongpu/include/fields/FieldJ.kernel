/**
 * Copyright 2013 Axel Huebl, Heiko Burau, Rene Widera
 *
 * This file is part of PIConGPU. 
 * 
 * PIConGPU is free software: you can redistribute it and/or modify 
 * it under the terms of the GNU General Public License as published by 
 * the Free Software Foundation, either version 3 of the License, or 
 * (at your option) any later version. 
 * 
 * PIConGPU is distributed in the hope that it will be useful, 
 * but WITHOUT ANY WARRANTY; without even the implied warranty of 
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the 
 * GNU General Public License for more details. 
 * 
 * You should have received a copy of the GNU General Public License 
 * along with PIConGPU.  
 * If not, see <http://www.gnu.org/licenses/>. 
 */

#ifndef FIELDJ_KERNEL
#define	FIELDJ_KERNEL

#include "types.h"
#include "particles/frame_types.hpp"
#include "basicOperations.hpp"

#include "simulation_defines.hpp"

#include "FieldJ.hpp"
#include "particles/memory/boxes/ParticlesBox.hpp"


#include "algorithms/Velocity.hpp"

#include "memory/boxes/CachedBox.hpp"
#include "dimensions/DataSpaceOperations.hpp"
#include "nvidia/functors/Add.hpp"
#include "mappings/threads/ThreadCollective.hpp"
#include "algorithms/Set.hpp"

#include "particles/frame_types.hpp"

namespace picongpu
{

using namespace PMacc;

typedef typename FieldJ::DataBoxType J_DataBox;

template<int workerMultiplier, class BlockDescription_, uint32_t AREA, class JBox, class ParBox, class Mapping, class FrameSolver>
__global__ void kernelComputeCurrent(JBox fieldJ,
                                     ParBox boxPar, FrameSolver frameSolver, Mapping mapper)
{
    typedef typename ParBox::FrameType FrameType;
    typedef typename Mapping::SuperCellSize SuperCellSize;

    const uint32_t cellsPerSuperCell = SuperCellSize::elements;

    const DataSpace<simDim> block(mapper.getSuperCellIndex(DataSpace<simDim > (blockIdx)));
    const DataSpace<simDim > threadIndex(threadIdx);

    /* thread id, can be greater than cellsPerSuperCell*/
    const int linearThreadIdx = DataSpaceOperations<simDim>::template map<SuperCellSize > (threadIndex);

    const uint32_t virtualBlockId = linearThreadIdx / cellsPerSuperCell;
    /* move linearThreadIdx for all threads to [0;cellsPerSuperCell) */
    const int virtualLinearId = linearThreadIdx - (virtualBlockId * cellsPerSuperCell);


    __shared__ FrameType * frame[workerMultiplier];
    __shared__ bool isValid[workerMultiplier];
    __shared__ lcellId_t particlesInSuperCell;

    __syncthreads(); /*wait that all shared memory is initialised*/

    if (linearThreadIdx == 0)
    {
        frame[0] = &(boxPar.getLastFrame(block, isValid[0]));
        particlesInSuperCell = boxPar.getSuperCell(block).getSizeLastFrame();
        /* Set all isValid flags with id >0 to false.
         * isValid[0] is already initialized!!
         * Read valid frames.
         */
        for (int i = 1; i < workerMultiplier; ++i)
        {
            isValid[i] = false;
            if (isValid[i - 1])
                frame[i] = &(boxPar.getPreviousFrame(*(frame[i - 1]), isValid[i]));
        }
    }
    __syncthreads();

    /* only leave calculation if we have no frames
     * If we have a frame than we need all threads for
     * filling shared memory
     */
    if (!(isValid[0]))
        return;

    /* This memory is used by all virtual blocks*/
    PMACC_AUTO(cachedJ, CachedBox::create < 0, typename JBox::ValueType > (BlockDescription_()));

    Set<typename JBox::ValueType > set(float3_X(0.0, 0.0, 0.0));
    ThreadCollective<BlockDescription_, cellsPerSuperCell * workerMultiplier> collectivSet(linearThreadIdx);
    collectivSet(set, cachedJ);

    /* all threads of a virtual block will leave if it has no frame */
    if (!(isValid[virtualBlockId]))
        return;

    __syncthreads();
    /* all threads can check isValid[0] because we know that
     * we are at end of frame list if isValid[0] is not valid
     */
    while (isValid[virtualBlockId])
    {
        /* virtualBlockId != 0 no need to check particlesInSuperCell 
         * because only last frame is not full filled
         */
        if (virtualBlockId != 0 || linearThreadIdx < particlesInSuperCell)
        {
            frameSolver(*(frame[virtualBlockId]),
                        virtualLinearId,
                        cachedJ);
        }
        __syncthreads();
        if (linearThreadIdx == 0)
        {
            particlesInSuperCell = SuperCellSize::elements;
            isValid[0] = isValid[workerMultiplier - 1];
            if (isValid[workerMultiplier - 1])
                frame[0] = &(boxPar.getPreviousFrame(*(frame[workerMultiplier - 1]), isValid[0]));
            /* read all frames in sequential order
             * but only if workerMultiplier>=1 */
            for (int i = 1; i < workerMultiplier; ++i)
            {
                isValid[i] = false;
                if (isValid[i - 1])
                    frame[i] = &(boxPar.getPreviousFrame(*(frame[i - 1]), isValid[i]));
            }
        }
        __syncthreads();
    }
    /* we wait that all threads finish the loop*/
    __syncthreads();
    /* Write to global memory
     * We only use virtual block 0, other frame could have left already */
    if (virtualBlockId == 0)
    {
        nvidia::functors::Add add;
        const DataSpace<simDim> blockCell = block * SuperCellSize::getDataSpace();
        ThreadCollective<BlockDescription_, cellsPerSuperCell> collectivAdd(linearThreadIdx);
        PMACC_AUTO(fieldJBlock, fieldJ.shift(blockCell));
        collectivAdd(add, fieldJBlock, cachedJ);
    }
    __syncthreads();
}

template<class ParticleAlgo, class Velocity, class TVec>
struct ComputeCurrentPerFrame
{

    HDINLINE ComputeCurrentPerFrame(const float_X deltaTime) :
    deltaTime(deltaTime)
    {
    }

    template<class FrameType, class BoxJ >
    DINLINE void operator()(FrameType& frame, const int localIdx, BoxJ & jBox)
    {

        PMACC_AUTO(particle, frame[localIdx]);
        const float_X weighting = particle[weighting_];
        const floatD_X pos = particle[position_];
        const int particleCellIdx = particle[localCellIdx_];
        const float_X charge = particle.getCharge(weighting);
        const DataSpace<simDim> localCell(DataSpaceOperations<simDim>::template map<TVec > (particleCellIdx));

        Velocity velocity;
        const float3_X vel = velocity(
                                      particle[momentum_],
                                      particle.getMass(weighting));
        PMACC_AUTO(fieldJShiftToParticle, jBox.shift(localCell));
        ParticleAlgo perParticle;
        perParticle(fieldJShiftToParticle,
                    pos,
                    vel,
                    charge,
                    deltaTime
                    );
    }

private:
    const PMACC_ALIGN(deltaTime, float);
};

template<class Mapping>
__global__ void kernelAddCurrentToE(typename FieldE::DataBoxType fieldE,
                                    J_DataBox fieldJ,
                                    Mapping mapper)
{

    const DataSpace<simDim> blockCell(
                                      mapper.getSuperCellIndex(DataSpace<simDim > (blockIdx))
                                      * Mapping::SuperCellSize::getDataSpace()
                                      );
    const DataSpace<Mapping::Dim> cell(blockCell + DataSpace<simDim > (threadIdx));

    // Amperes Law:
    //   Change of the dE = - j / EPS0 * dt
    //                        j = current density (= current per area)
    //                          = fieldJ
    const float_X deltaT = DELTA_T;
    fieldE(cell) -= fieldJ(cell) * (float_X(1.0) / EPS0) * deltaT;
}

template<class Mapping>
__global__ void kernelBashCurrent(J_DataBox fieldJ,
                                  J_DataBox targetJ,
                                  DataSpace<simDim> exchangeSize,
                                  DataSpace<simDim> direction,
                                  Mapping mapper)
{
    const DataSpace<simDim> blockCell(
                                      mapper.getSuperCellIndex(DataSpace<simDim > (blockIdx))
                                      * Mapping::SuperCellSize::getDataSpace()
                                      );
    const DataSpace<Mapping::Dim> threadIndex(threadIdx);
    const DataSpace<Mapping::Dim> sourceCell(blockCell + threadIndex);

    /*origin in area from local GPU*/
    DataSpace<simDim> nullSourceCell(
                                     mapper.getSuperCellIndex(DataSpace<simDim > ())
                                     * Mapping::SuperCellSize::getDataSpace()
                                     );
    DataSpace<simDim> targetCell(sourceCell - nullSourceCell);

    for (uint32_t d = 0; d < simDim; ++d)
    {
        if (direction[d] == -1)
        {
            if (threadIndex[d] < tile_size[d] - exchangeSize[d]) return;
            targetCell[d] -= tile_size[d] - exchangeSize[d];
        }
        else if ((direction[d] == 1) && (threadIndex[d] >= exchangeSize[d])) return;
    }

    targetJ(targetCell) = fieldJ(sourceCell);
}

template<class Mapping>
__global__ void kernelInsertCurrent(J_DataBox fieldJ,
                                    J_DataBox sourceJ,
                                    DataSpace<simDim> exchangeSize,
                                    DataSpace<simDim> direction,
                                    Mapping mapper)
{
    const DataSpace<Mapping::Dim> threadIndex(threadIdx);
    const DataSpace<simDim> blockCell(
                                      mapper.getSuperCellIndex(DataSpace<simDim > (blockIdx))
                                      * Mapping::SuperCellSize::getDataSpace()
                                      );
    DataSpace<Mapping::Dim> targetCell(blockCell + threadIndex);

    /*origin in area from local GPU*/
    DataSpace<simDim> nullSourceCell(
                                     mapper.getSuperCellIndex(DataSpace<simDim > ())
                                     * Mapping::SuperCellSize::getDataSpace()
                                     );
    DataSpace<simDim> sourceCell(targetCell - nullSourceCell);

    for (uint32_t d = 0; d < simDim; ++d)
    {
        if (direction[d] == 1)
        {
            if (threadIndex[d] < tile_size[d] - exchangeSize[d]) return;
            sourceCell[d] -= tile_size[d] - exchangeSize[d];
            targetCell[d] -= tile_size[d];
        }
        else if (direction[d] == -1)
        {
            if (threadIndex[d] >= exchangeSize[d]) return;
            targetCell[d] += tile_size[d];
        }
    }
    
    fieldJ(targetCell) += sourceJ(sourceCell);
}

}


#endif  //end FIELDJ_KERNEL
