/**
 * Copyright 2013-2014 Felix Schmitt, Heiko Burau, Rene Widera
 *
 * This file is part of libPMacc.
 *
 * libPMacc is free software: you can redistribute it and/or modify
 * it under the terms of either the GNU General Public License or
 * the GNU Lesser General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * libPMacc is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License and the GNU Lesser General Public License
 * for more details.
 *
 * You should have received a copy of the GNU General Public License
 * and the GNU Lesser General Public License along with libPMacc.
 * If not, see <http://www.gnu.org/licenses/>.
 */

#include "types.h"
#include "particles/memory/boxes/ParticlesBox.hpp"
#include "particles/memory/boxes/PushDataBox.hpp"
#include "particles/memory/boxes/PopDataBox.hpp"
#include "particles/memory/boxes/TileDataBox.hpp"
#include "dimensions/DataSpaceOperations.hpp"
#include "mappings/kernel/ExchangeMapping.hpp"
#include "particles/memory/boxes/ExchangePushDataBox.hpp"
#include "particles/memory/boxes/ExchangePopDataBox.hpp"

#include "particles/operations/Assign.hpp"
#include "particles/operations/Deselect.hpp"
#include "traits/NumberOfExchanges.hpp"
#include "nvidia/atomic.hpp"

namespace PMacc
{

template<typename T_ParticleBox, typename T_SuperCellIdxType>
DINLINE bool getPreviousFrameAndRemoveLastFrame(typename T_ParticleBox::FrameType*& frame,
                                                T_ParticleBox& pb,
                                                const T_SuperCellIdxType& superCellIdx)
{
    bool isFrameValid = false;
    frame = &(pb.getPreviousFrame(*frame, isFrameValid));
    const bool hasMoreFrames = pb.removeLastFrame(superCellIdx);
    return isFrameValid && hasMoreFrames;
}

/*! This kernel move particles to the next supercell
 * This kernel can only run with a double checker board
 */
template<class FRAME, class Mapping>
__global__ void kernelShiftParticles(ParticlesBox<FRAME, Mapping::Dim> pb, Mapping mapper)
{

    using namespace particles::operations;

    /* Exchanges in 2D=8 and in 3D=26
     */
    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim,
        Exchanges = traits::NumberOfExchanges<Dim>::value
    };


    //\todo: testen ob es schneller ist, erst zu flushen wennn Source voll ist
    __shared__ FRAME * destFrames[Exchanges];
    __shared__ int destFramesCounter[Exchanges]; //count particles per frame
    __shared__ bool anyDestFrameFull; //flag if any destination Frame is full

    __shared__ FRAME *frame;
    __shared__ bool isFrameValid;
    __shared__ bool mustShift;

    __syncthreads(); /*wait that all shared memory is initialised*/

    DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex(DataSpace<Dim > (blockIdx));

    if (threadIdx.x == 0)
    {
        mustShift = pb.getSuperCell(superCellIdx).mustShift();
        if (mustShift)
        {
            //only do anything if we must shift a frame
            pb.getSuperCell(superCellIdx).setMustShift(false);
            anyDestFrameFull = false;
            frame = &(pb.getFirstFrame(superCellIdx, isFrameValid));
        }
    }

    __syncthreads();
    if (!mustShift || isFrameValid == false) return;

    //!\todo: find a way without so many flags
    bool isNeighborFrame = false;
    //init
    if (threadIdx.x < Exchanges)
    {
        DataSpace<Dim> relative = superCellIdx + Mask::getRelativeDirections<Dim > (threadIdx.x + 1);
        destFramesCounter[threadIdx.x] = 0;
        destFrames[threadIdx.x] = &(pb.getLastFrame(relative, isNeighborFrame));
        if (isNeighborFrame)
        {
            destFramesCounter[threadIdx.x] = pb.getSuperCell(relative).getSizeLastFrame();
            if (destFramesCounter[threadIdx.x] == TileSize)
            {
                //don't use last frame is it is full
                destFrames[threadIdx.x] = NULL;
                destFramesCounter[threadIdx.x] = 0;
                isNeighborFrame = false;
            }
        }
        else
            destFrames[threadIdx.x] = NULL;

    }
    __syncthreads();

    do
    {
        lcellId_t destParticleIdx = INV_LOC_IDX;

        //switch to value to [-2, EXCHANGES - 1]
        //-2 is no particle
        //-1 is particle but it is not shifted
        const int direction = (*frame)[threadIdx.x][multiMask_] - 2;
        if (direction >= 0) //\todo: weglassen
        {
            destParticleIdx = atomicAdd(&(destFramesCounter[direction]), 1);
            (*frame)[threadIdx.x][multiMask_] = 0; //delete particle, later we copy this particle without multiMask
            if (destParticleIdx >= TileSize) anyDestFrameFull = true;
        }
        __syncthreads();
        if (threadIdx.x < Exchanges &&
            destFramesCounter[threadIdx.x] > 0 &&
            destFrames[threadIdx.x] == NULL)
        {
            destFrames[threadIdx.x] = &(pb.getEmptyFrame());
        }
        __syncthreads();
        if (anyDestFrameFull) /*we must do two flushes, after the first we hang on a new empty frame*/
        {
            if (direction >= 0 && destParticleIdx < TileSize)
            {
                PMACC_AUTO(parDestFull,
                           (*(destFrames[direction]))[destParticleIdx]
                           );
                parDestFull[multiMask_] = 1;
                PMACC_AUTO(parSrc, (*frame)[threadIdx.x]);
                PMACC_AUTO(parDest, deselect<multiMask>(parDestFull));
                assign(parDest, parSrc);

            }
            __syncthreads();
            if (threadIdx.x < Exchanges)
            {
                //append all full frames to destination
                if (destFramesCounter[threadIdx.x] >= TileSize)
                {
                    destFramesCounter[threadIdx.x] -= TileSize;
                    DataSpace<Dim> relative = superCellIdx + Mask::getRelativeDirections<Dim > (threadIdx.x + 1);
                    if (isNeighborFrame)
                    {
                        pb.getSuperCell(relative).setSizeLastFrame(TileSize);
                        isNeighborFrame = false;

                    }
                    else
                    {
                        //this is the cause that this kernel can't run without double checker board
                        pb.setAsFirstFrame(*(destFrames[threadIdx.x]),
                                           relative);
                    }

                    if (destFramesCounter[threadIdx.x] > 0)
                        destFrames[threadIdx.x] = &(pb.getEmptyFrame());
                    else
                        destFrames[threadIdx.x] = NULL;
                }
                anyDestFrameFull = false;
            }
            __syncthreads();
            if (direction >= 0 && destParticleIdx >= TileSize)
            {
                destParticleIdx -= TileSize;
                PMACC_AUTO(parDestFull, (*(destFrames[direction]))[destParticleIdx]);
                /*enable particle*/
                parDestFull[multiMask_] = 1;
                /* we not update multiMask because copy from mem to mem is too slow
                 * we have enabled particle explicitly */
                PMACC_AUTO(parDest, deselect<multiMask>(parDestFull));
                PMACC_AUTO(parSrc, (*frame)[threadIdx.x]);
                assign(parDest, parSrc);
            }
        }
        else
        {
            //only flush because no destination is full
            if (direction >= 0)
            {
                PMACC_AUTO(parDestFull, (*(destFrames[direction]))[destParticleIdx]);
                /*enable particle*/
                parDestFull[multiMask_] = 1;
                /* we not update multiMask because copy from mem to mem is to slow
                 * we have enabled particle explicit */
                PMACC_AUTO(parDest, deselect<multiMask>(parDestFull));
                PMACC_AUTO(parSrc, (*frame)[threadIdx.x]);
                assign(parDest, parSrc);
            }
        }

        __syncthreads();
        if (threadIdx.x == 0)
        {
            frame = &(pb.getNextFrame(*frame, isFrameValid));
        }
        __syncthreads();


    }
    while (isFrameValid);


    if (threadIdx.x < Exchanges)
    {
        if (destFramesCounter[threadIdx.x] > 0)
        {
            DataSpace<Dim> relative = superCellIdx + Mask::getRelativeDirections<Dim > (threadIdx.x + 1);
            if (!isNeighborFrame)
            {
                pb.setAsLastFrame(*(destFrames[threadIdx.x]),
                                  relative);
            }
            pb.getSuperCell(relative).setSizeLastFrame(destFramesCounter[threadIdx.x]);
        }
        else if (destFrames[threadIdx.x] != NULL)
        {
            if (!isNeighborFrame)
                pb.removeFrame(*(destFrames[threadIdx.x]));
        }
    }
}

template<class FRAME, class Mapping>
__global__ void kernelFillGapsLastFrame(ParticlesBox<FRAME, Mapping::Dim> pb, Mapping mapper)
{
    using namespace particles::operations;

    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim
    };

    DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex(DataSpace<Dim > (blockIdx));

    __shared__ FRAME *lastFrame;
    __shared__ bool isValid;

    __shared__ int gapIndices_sh[TileSize];
    __shared__ int counterGaps;
    __shared__ int counterParticles;

    __shared__ int srcGap;

    __syncthreads(); /*wait that all shared memory is initialised*/

    if (threadIdx.x == 0)
    {
        lastFrame = &(pb.getLastFrame(DataSpace<Dim > (superCellIdx), isValid));
        counterGaps = 0;
        counterParticles = 0;
        srcGap = 0;
    }
    __syncthreads();


    if (isValid)
    {
        //count particles in last frame
        const bool isParticle = (*lastFrame)[threadIdx.x][multiMask_];
        if (isParticle == true) //\todo: bits z√§hlen
        {
            nvidia::atomicAllInc(&counterParticles);
        }
        __syncthreads();

        if (threadIdx.x < counterParticles && isParticle == false)
        {
            const int localGapIdx = nvidia::atomicAllInc(&counterGaps);
            gapIndices_sh[localGapIdx] = threadIdx.x;
        }
        __syncthreads();
        if (threadIdx.x >= counterParticles && isParticle)
        {
            //any particle search a gap
            const int srcGapIdx = nvidia::atomicAllInc(&srcGap);
            const int gapIdx = gapIndices_sh[srcGapIdx];
            PMACC_AUTO(parDestFull, ((*lastFrame)[gapIdx]));
            /*enable particle*/
            parDestFull[multiMask_] = 1;
            /* we not update multiMask because copy from mem to mem is to slow
             * we have enabled particle explicit */
            PMACC_AUTO(parDest, deselect<multiMask>(parDestFull));
            PMACC_AUTO(parSrc, ((*lastFrame)[threadIdx.x]));
            assign(parDest, parSrc);
            parSrc[multiMask_] = 0; //delete old partice
        }
    }
    if (threadIdx.x == 0)
        pb.getSuperCell(superCellIdx).setSizeLastFrame(counterParticles);

}

template<class FRAME, class Mapping>
__global__ void kernelFillGaps(ParticlesBox<FRAME, Mapping::Dim> pb, Mapping mapper)
{
    using namespace particles::operations;

    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim
    };

    DataSpace<Dim> superCellIdx(mapper.getSuperCellIndex(DataSpace<Dim > (blockIdx)));

    //data copied from right (last) to left (first)
    __shared__ FRAME *firstFrame;
    __shared__ FRAME *lastFrame;
    __shared__ bool isValid;

    __shared__ int particleIndices_sh[TileSize];
    __shared__ int counterGaps;
    __shared__ int counterParticles;

    __syncthreads(); /*wait that all shared memory is initialised*/

    if (threadIdx.x == 0)
    {
        bool tmpValid;
        firstFrame = &(pb.getFirstFrame(DataSpace<Dim > (superCellIdx), tmpValid));
        lastFrame = &(pb.getLastFrame(DataSpace<Dim > (superCellIdx), isValid));
        isValid = isValid && tmpValid;
    }
    __syncthreads();

    while (isValid)
    {
        if (firstFrame == lastFrame) break; /*exit loop if both frames are equal*/

        if (threadIdx.x == 0)
        {
            //\todo: check if we need control thread or can write to shared with all threads
            counterGaps = 0;
            counterParticles = 0;
        }
        int localGapIdx = INV_LOC_IDX; //later we cann call localGapIdx < X because X<INV_LOC_IDX

        __syncthreads();

        // find gaps
        if ((*firstFrame)[threadIdx.x][multiMask_] == 0)
        {
            localGapIdx = nvidia::atomicAllInc(&counterGaps);
        }
        __syncthreads();

        if (counterGaps == 0)
        {
            if (threadIdx.x == 0)
            {
                firstFrame = &(pb.getNextFrame(*firstFrame, isValid));
            }
            __syncthreads(); //wait control thread search new frame
            continue; //check next frame
        }

        // search particles for gaps
        if ((*lastFrame)[threadIdx.x][multiMask_] == 1)
        {
            int localParticleIdx = nvidia::atomicAllInc(&counterParticles);
            particleIndices_sh[localParticleIdx] = threadIdx.x;
        }
        __syncthreads();
        if (localGapIdx < counterParticles)
        {
            const int parIdx = particleIndices_sh[localGapIdx];
            PMACC_AUTO(parDestFull, ((*firstFrame)[threadIdx.x]));
            /*enable particle*/
            parDestFull[multiMask_] = 1;
            /* we not update multiMask because copy from mem to mem is to slow
             * we have enabled particle explicit */
            PMACC_AUTO(parDest, deselect<multiMask>(parDestFull));
            PMACC_AUTO(parSrc, ((*lastFrame)[parIdx]));
            assign(parDest, parSrc);
            parSrc[multiMask_] = 0;
        }
        __syncthreads();
        if (threadIdx.x == 0)
        {
            bool isFrameValid = false;
            if (counterGaps < counterParticles)
            {
                //any gap in the first frame is filled
                firstFrame = &(pb.getNextFrame(*firstFrame, isFrameValid));
            }
            else if (counterGaps > counterParticles)
            {
                //we need more particles
                isFrameValid = getPreviousFrameAndRemoveLastFrame(lastFrame, pb, superCellIdx);
            }
            else if (counterGaps == counterParticles)
            {
                isFrameValid = getPreviousFrameAndRemoveLastFrame(lastFrame, pb, superCellIdx);
                if (isFrameValid && lastFrame != firstFrame)
                {
                    firstFrame = &(pb.getNextFrame(*firstFrame, isFrameValid));
                }

            }
            isValid = isFrameValid;
        }
        __syncthreads();
    }
}

template< class T_ParticleBox, class Mapping>
__global__ void kernelDeleteParticles(T_ParticleBox pb,
                                      Mapping mapper)
{
    using namespace particles::operations;

    typedef T_ParticleBox ParticleBox;
    typedef typename ParticleBox::FrameType FrameType;

    enum
    {
        Dim = Mapping::Dim
    };

    DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex(DataSpace<Dim > (blockIdx));
    const int linearThreadIdx = threadIdx.x;

    __shared__ FrameType *frame;
    __shared__ bool isValid;

    __syncthreads(); /*wait that all shared memory is initialised*/

    if (linearThreadIdx == 0)
    {
        frame = &(pb.getLastFrame(superCellIdx, isValid));
    }

    __syncthreads();

    while (isValid)
    {

        PMACC_AUTO(particle, ((*frame)[linearThreadIdx]));
        particle[multiMask_] = 0; //delete particle

        __syncthreads();

        if (linearThreadIdx == 0)
        {
            //always remove the last frame
            isValid = getPreviousFrameAndRemoveLastFrame(frame, pb, superCellIdx);
        }
        __syncthreads();
    }

    if (linearThreadIdx == 0)
        pb.getSuperCell(superCellIdx).setSizeLastFrame(0);

}

template< class FRAME, class BORDER, class Mapping>
__global__ void kernelBashParticles(ParticlesBox<FRAME, Mapping::Dim> pb,
                                    ExchangePushDataBox<vint_t, BORDER, Mapping::Dim - 1 > border,
                                    Mapping mapper)
{
    using namespace particles::operations;

    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim
    };

    DataSpace<Dim> superCellIdx = mapper.getSuperCellIndex(DataSpace<Dim > (blockIdx));

    __shared__ int numBashedParticles;
    __shared__ FRAME *frame;
    __shared__ bool isValid;
    __shared__ bool hasMemory;
    __shared__ TileDataBox<BORDER> tmpBorder;

    __syncthreads(); /*wait that all shared memory is initialised*/

    if (threadIdx.x == 0)
    {
        hasMemory = true;
        frame = &(pb.getLastFrame(superCellIdx, isValid));
    }
    //\todo: eventuell ist es schneller, parallelen und seriellen Code zu trennen
    __syncthreads();
    while (isValid && hasMemory)
    {
        lcellId_t bashIdx = INV_LOC_IDX;
        if (threadIdx.x == 0)
            numBashedParticles = 0;
        __syncthreads();

        if ((*frame)[threadIdx.x][multiMask_] == 1)
        {
            bashIdx = nvidia::atomicAllInc(&numBashedParticles);
        }
        __syncthreads();

        if (numBashedParticles > 0)
        {

            if (threadIdx.x == 0)
            {
                // DataSpaceOperations<DIM2>::reduce computes target position for domainTile and exchangeType
                tmpBorder = border.pushN(numBashedParticles,
                                         DataSpaceOperations<Dim>::reduce(
                                                                          superCellIdx,
                                                                          mapper.getExchangeType()));
                if (tmpBorder.getSize() < numBashedParticles)
                    hasMemory = false;
            }
            __syncthreads();

            if (bashIdx != INV_LOC_IDX && bashIdx < tmpBorder.getSize())
            {
                PMACC_AUTO(parDest, tmpBorder[bashIdx][0]);
                PMACC_AUTO(parSrc, ((*frame)[threadIdx.x]));
                assign(parDest, parSrc);
                parSrc[multiMask_] = 0;
            }
            __syncthreads();

            if (threadIdx.x == 0 && hasMemory)
            {
                //always remove the last frame
                isValid=getPreviousFrameAndRemoveLastFrame(frame,pb,superCellIdx);
            }
        }
        else
        {
            //if we had no particles to copy than we are the last and only frame
            if (threadIdx.x == 0)
            {
                isValid=getPreviousFrameAndRemoveLastFrame(frame,pb,superCellIdx);
            }
        }
        __syncthreads();
    }
    if (threadIdx.x == 0)
        pb.getSuperCell(superCellIdx).setSizeLastFrame(0);

}

template<class FRAME, class BORDER, class Mapping>
__global__ void kernelInsertParticles(ParticlesBox<FRAME, Mapping::Dim> pb,
                                      ExchangePopDataBox<vint_t, BORDER, Mapping::Dim - 1 > border,
                                      Mapping mapper)
{

    using namespace particles::operations;

    enum
    {
        TileSize = math::CT::volume<typename Mapping::SuperCellSize>::type::value,
        Dim = Mapping::Dim
    };

    __shared__ FRAME* frame;
    __shared__ int elementCount;
    __shared__ TileDataBox<BORDER> tmpBorder;

    __syncthreads(); /*wait that all shared memory is initialised*/

    DataSpace < Mapping::Dim - 1 > superCell;

    if (threadIdx.x == 0)
    {
        tmpBorder = border.pop(superCell);
        elementCount = tmpBorder.getSize();
        if (elementCount > 0)
        {
            frame = &(pb.getEmptyFrame());
        }
    }
    __syncthreads();
    if (threadIdx.x < elementCount)
    {
        PMACC_AUTO(parDestFull, ((*frame)[threadIdx.x]));
        parDestFull[multiMask_] = 1;
        PMACC_AUTO(parSrc, ((tmpBorder[threadIdx.x])[0]));
        /*we know that source has no multiMask*/
        PMACC_AUTO(parDest, deselect<multiMask>(parDestFull));
        assign(parDest, parSrc);
    }
    /*if this syncronize fix the kernel crash in spezial cases,
     * I can't tell why.
     */
    __syncthreads();
    if ((threadIdx.x == 0) && (elementCount > 0))
    {
        // compute the super cell position in target frame to insert into
        ///\todo: offset == simulation border should be passed to this func instead of being created here
        DataSpace<Dim> dstSuperCell = DataSpaceOperations < Dim - 1 > ::extend(superCell,
                                                                               mapper.getExchangeType(),
                                                                               mapper.getGridSuperCells(),
                                                                               DataSpace<Dim>::create(mapper.getGuardingSuperCells()));

        pb.setAsLastFrame(*frame, dstSuperCell);
    }


}



} //namespace PMacc

